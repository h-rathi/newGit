name: Run price scraper (twice daily IST + manual with logging)

# Schedule: runs twice a day.
# 08:30 IST -> 03:00 UTC
# 20:30 IST -> 15:00 UTC
on:
  schedule:
    - cron: '0 3,15 * * *'
  workflow_dispatch: {}

permissions:
  contents: write

jobs:
  run-scraper:
    runs-on: ubuntu-latest
    env:
      TZ: Asia/Kolkata

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright beautifulsoup4 openpyxl lxml

      - name: Install Playwright browsers (with deps)
        run: |
          python -m playwright install --with-deps

      - name: Ensure output directory exists
        run: |
          mkdir -p outputs

      - name: Run scraper (headless) and capture logs
        id: run-scraper
        run: |
          set -o pipefail

          # run script, capture stdout+stderr to run.log while still printing to job log
          python script.py 2>&1 | tee run.log
          rc=${PIPESTATUS[0]}
          echo "$rc" > run_exit_code.txt

          if [ "$rc" -ne 0 ]; then
            echo "❌ Script exited with code $rc"
          else
            echo "✅ Script finished successfully (exit code 0)"
          fi

          # return the same exit code so the job step reflects success/failure
          exit $rc

      - name: Commit and push results (only on success)
        if: success()
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Add only the outputs folder and any json files (cookies etc.)
          git add outputs || true
          git add *.json || true

          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "chore: update scraped results (automated run: $(date -u +'%Y-%m-%d %H:%M:%S UTC'))" || true
            # Push back to the same branch that triggered the workflow
            git push origin HEAD:${{ github.ref_name }}
          else
            echo "No changes to commit."
          fi

      - name: Collect debug info & show tail of run log
        if: always()
        run: |
          echo "---- run exit code ----"
          if [ -f run_exit_code.txt ]; then cat run_exit_code.txt; else echo "no exit code file"; fi

          echo "---- last 200 lines of run.log (if exists) ----"
          if [ -f run.log ]; then tail -n 200 run.log || true; else echo "run.log not found"; fi

          echo "---- outputs dir listing (if exists) ----"
          if [ -d outputs ]; then ls -la outputs || true; else echo "outputs dir not found"; fi

          echo "---- json files listing (if any) ----"
          ls -la *.json || echo "no json files found"

          echo "---- potentially updated files ----"
          if [ -f outputs/results.xlsx ]; then echo "outputs/results.xlsx -> exists"; else echo "outputs/results.xlsx -> not found"; fi
          for f in *.json; do
            if [ -f "$f" ]; then echo "$f -> exists"; else break; fi
          done

          echo "---- git status (for debugging) ----"
          git status --porcelain || true

      - name: Upload run log artifact (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: run-log
          path: run.log

      - name: Upload outputs + json artifacts (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-outputs
          path: |
            outputs/**
            *.json
